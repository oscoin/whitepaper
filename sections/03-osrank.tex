\section{Osrank}
\label{s:osrank}

\def\Graph{\mathsf{Graph}}
\def\proj{\mathsf{proj}}
\def\user{\mathsf{user}}
\def\dep{\mathsf{dep}}
\def\own{\mathsf{own}}
\def\coown{\mathsf{own}^\circ}
\def\contrib{\mathsf{contrib}}
\def\cocontrib{\mathsf{contrib}^\circ}

Since one of the fundamental mechanisms of \oscoin{} is to distribute a portion
of newly minted \oscoin{} to high-value projects on the network, the protocol
must reach consensus on which projects are ``high value''. To choose which
projects receive \oscoin{}, and in which proportions, the network uses
\osrank{}, which is a variant of the well-know \pagerank{}
algorithm~\cite{pagerank}, applied to the graph of relationships between
projects and contributions on the network, particularly project
\emph{dependencies}. The output of the \osrank{} algorithm is a score
$\omega(P)$ associated to each project $P$.

\subsection{Intuition}

While the importance of an open source software package is highly subjective,
valuable information about a project's relative importance can be
surfaced by studying the structure of open source software through
dependencies and contributions.

The PageRank algorithm allowed Google to scale Internet search by
reading what the hypertextual structure of the Web indicated about the
relative importance of its contents. Similarly, the linked graph of open
source software dependencies and contributions is a resource
indicating implicit trust within open source communities and the relative
value within that structure.

\subsection{Rationale}

While it may be clear that value is being produced by a system as a whole, it is
often unclear how much value particular subsystems are
contributing. Furthermore, subsystems have inherently differing capacities to
transform value into revenue: subsystems at the boundaries with other domains
are at an advantage, even though they may (transitively) derive much of their
value from other subsystems. This imbalance of value flows into and out of
subsystems is detrimental to the system as a whole.

Thankfully, human activity does not happen in a void\footnote{Space
  exploration will be addressed in a subsequent paper.}: be it
knowledge work, content/media creation, financial activity, etc.,
entities interact with one another in meaningful ways that are highly
influenced by the relative value each entity has with respect to the
system as a whole. Crucially, during this activity, a trail of
\emph{artefacts} (hypermedia links, contracts, transactions,
dependencies etc.) is produced; concrete manifestations
of the relationships between the various entities.

% TODO: 'human activity does not happen in a void' is a little casual sounding for
% this paper. also I'm not sure there's really enough context to know what 'human activity'
% means when you reach this point in the paper.

% TODO: do we have a standard name for a project OR a contributor (node maybe)
% entity is a little vague and I think we should try to keep terminology consistant

The basic insight of \pagerank{} and similar metrics, is that by
stochastic simulation of meaningful activity traces of system agents,
producing trails of artefacts consistent with observations, one can
learn about the value flows between subsystems, and hence approximate
the underlying value distribution. In the case of \pagerank{} one
simulates a human searching for high-relevance data over the internet,
following a chain of links. A sophisticated algorithm would use as
many heuristics as possible for choosing the next link to follow (as a
real human would), \eg{} evaluating the relevance of the link-text. If
computational resources are scarce, the crudest algorithm simply picks
the next link at random, and this is what produces the classic
\pagerank{} formula which has proven so successful on the Web.

\subsection{Notation}

In this section we will use the following conventions: A \emph{graph} refers to
a finite directed graph. For such a graph $G$ the vertex set is denoted $V(G)$
and the edge-set is denoted $E(G) \subseteq V^2$. An edge $e = (x,y)$ of $G$ is
denoted $x \xrightarrow[]{e} y$. Given a subset $X$ of the vertices of $G$,
$G[X]$ denotes the \emph{induced subgraph} on $X$, that is, the graph with $X$
as the set of vertices and as edges the set
$\{ x \xrightarrow[]{e} y \mid e \in E(G), \{x,y\} \subseteq X\}$. A \emph{walk}
of length $n$ in a graph $G$ is a morphism of graphs $L_n \to G$ where $L_n$ is
the $n$-th linear-graph: $V(L_n) = \{i \in \mathbb{N} \mid i \leq n \}$,
$E(L_n) = \{ (i,i+1) \in \mathbb{N}^2 \mid i < n \}$.

\subsection{Ranking entities in \oscoin{}}
\label{s:netgraph}

The artefacts related to OSS development which are captured on the \oscoin{}
ledger are:
\begin{itemize}
  \item Ownership of a project by a key,
  \item Dependencies between projects,
  \item Signed code contributions to projects.
\end{itemize}

We summarise these interactions with a weighted directed graph $G$
(Figure~\ref{fig:G}), the weights corresponding to the relative importance of
the edge, which can be set as parameters to the algorithm.  The weights on all
edges outgoing from a vertex sum to $1$.

\bigskip

\begin{center}
\begin{tikzpicture}[vertex/.style={draw,circle}, arr/.style={draw,thick,->}]
  \node[vertex] (p) at (2,0)  {\small $\proj$};
  \node[vertex] (u) at (-2,0) {\small $\user$};

  \draw[arr,looseness=9] (p) to[out=95,in=25] node[above] {\small $\dep \ (\frac{4}{7})$} (p);
  \draw[arr] (p) to[out=165,in=15] node[above]   {\small $\own \ (\frac{2}{7})$} (u);
  \draw[arr] (u) to[out=55,in=125] node[above]   {\small $\coown \ (\frac{3}{5})$} (p);
  \draw[arr] (p) to[out=195,in=-15] node[below]  {\small $\contrib \ (\frac{1}{7})$} (u);
  \draw[arr] (u) to[out=-55,in=-125] node[below] {\small $\cocontrib \ (\frac{2}{5})$} (p);
\end{tikzpicture}
\captionof{figure}{\small Entity relations in open source software development with example weights.\label{fig:G}}
\end{center}
\medskip

% TODO: include simulations description and results here.

Note that some of the edges are biderectional, but each direction is
weighted uniquely. For example both $\contrib$ and $\cocontrib$ pertain to
the same artefact: a contribution of code from a user to a
project. The edge $\contrib$ represents the statement \emph{the user
  is valuable to the project}. The edge $\cocontrib$ going in the
opposite direction represents the statement \emph{the project is
  valuable to the user}; the rationale for this less obvious flow is
that users are unlikely to invest time contributing to projects they
do not find useful.

% TODO: Make the above easier to grasp. Also maybe rephrase a little "is
% valueable to the project"

% TODO: Make sure 'bidirectional' is the correct terminology. Or are these two
% unidirectional edges?

While the graph of dependencies between projects is the most straightforward
indication that a projects derives value from another, adding edges corresponding
to contribution and ownership serves two purposes:
\begin{itemize}
\item The graph is directed: it flows from user-facing applications to core
  libraries. This biases the score greatly towards basic libraries and
  development tools. Incorporating developer contributions brings flows in the
  opposite direction that indicatie valued user-facing applications. For example,
  a fully-featured open source text editor is of high value to
  open source developers, yet it may never become an explicit dependency of another
  piece of software. However, developers contributing to this text editor are
  also likely to contribute to packages upon which the text editor depends, and this
  allows the algorithm to flow back up from utility packages to user-facing
  packages. For example, an open source developper may contribute
  heavily to both the \texttt{atom} text editor (mostly JavaScript), and to
  one of its dependencies, \texttt{tree-sitter}, an incremental parser written
  in Rust.
\item While the dependency graph alone is unlikely to adequately bridge
  differing domains, developers often contribute to their neighboring ecosystem and
  to their tooling such that these niches can interconnect. Thus a graph incorporating
  dependencies as well as contributions may be sufficiently connected to
  reveal the latent value of open source projects.
\end{itemize}

% TODO: The '(mostly JavaScript)' bit is confusing. Is the developer's contribution
% mostly in JS, or the Atom text editor itself?

The \oscoin{} network proposes to record these artefacts as
transactions in a blockchain, so that one may verifiably construct---and
reach consensus on---a unique finite directed graph $\netgraph$ over $G$
(\ie{} in the slice category $\Graph/G$). We will refer to $\netgraph$
as the \emph{network graph}.

With a properly constructed \emph{network graph} global value scores may be
assigned to entities according to a specific stochastic process, that is
\emph{random walks} simulating traces of activity in $\netgraph$ with sample
probabilities taken from $G$. For example: a contributor decides to
work on a high value project (probably at the border), contributes a
changeset, and in so doing adds a dependency to another project, which imports a
bug from an upstream package. The contributor therefore switches to fixing said
bug in the dependency, etc. Much like a simulation of a human
searching for information by clicking through links, this simulated activity
informs us on the value flows between subsystems within the wider OSS
ecosystem.

% TODO: I think the above example mixes too many value flows.

% TODO: 'at the border' should be more clearly articulated. what kind of
% border and why is this important?

% TODO: I'm actually not sure this story of the simulated random walk is clarifying
% there are more concise ways to describe monte carlo systems directly, as methods
% that sample from the probability distribution of possible graph traversals, each
% trajectory representing a chain of causal dependency, either on software or human
% activity.

This score, which we call \osrank{}, is used to distribute a portion of the
newly minted tokens to projects as a function of their value to the \oscoin{} network.

\subsection{Definition}

To implement \osrank{}, we use the following Monte Carlo-based algorithm: for
each vertex on the network, $R$ random walks are performed which start at that
vertex. To select the subsequent vertex, first an edge type is decided
by sampling edges according to the weights in $G$. The next step is specific to
the edge type:

\begin{itemize}
\item In the cases of $\dep$ and $\own$, all vertices are equiprobable.
\item In the cases of edges $x \xrightarrow[]{\coown} p$ and
  $x \xrightarrow[]{\cocontrib} p$ outgoing from a user $x$, a project $p$ is
  chosen with probability $\frac{p_x}{N_x}$, where $p_x$ is the number of
  contributions $x$ has contributed to $p$, and $N_x$ is the total number of
  contributions by $x$.
\item In the case of edges $p \xrightarrow[]{\contrib} x$, the users $x$ are
  chosen with probability $\frac{p_x}{N}$, where $N$ is the total number of
  contributions $p$ has received from all users.
\end{itemize}

At each step the walk might terminate with probability $1 - \epsilon_\proj$ at a
project vertex, and $1 - \epsilon_\user$ at a user vertex, (here
$\epsilon_\proj, \epsilon_\user \in (0,1)$ are the \emph{damping factors}). This
produces a set $W$ of $nR$ random walks, where $n$ is the total number of
vertices. The \osrank{} for a project $x$ is then:
\[
  \omega(x) = \frac{W_x \epsilon_\proj}{n R}
\]
where $W_x$ is the number of times all the walks in $W$ visit $x$, that is:
\[
W_x = \sum_{w \in W} |w[\{x\}]|.
\]
Similarly, the \osrank{} of a user $u$ is:
\[
  \omega(u) = \frac{W_u \epsilon_\user}{n R}.
\]
% TODO: "user" should rather be "contribution set"

\subsection{Sybil networks}

In order to maintain the integrity of the \oscoin{} graph,
illegitimate ecosystems must not be allowed to perpetuate, that is,
fraudulent project and contribution structures which have been instantiated
for the purpose of exploiting \osrank{}.
Such \emph{Sybil attacks} on \pagerank{} have been examined
in detail in previous work \cite{pagerank-sybil}.

To address this we propose a modification of the \pagerank{} algorithm based
on the ideas behind TrustRank~\cite{trustrank}, which involves two distinct
phases:

\begin{itemize}
\item In the first phase, all random walks begin at a vertex included in
  the initialization seed set $\seedset$, a subset of all project vertices.
  Otherwise the process remains the same. The resulting scores are biased towards
  interactions with the seed set, but are not used directly by the compensation
  mechanism. Instead a threshold $t$ is used to determine the legitimacy of entities: any entity
  falling below this threshold is not considered for the next phase. The output
  of this phase is a subgraph $\netgraph_t$ of the network graph.
\item In the second phase, the algorithm is run on the subgraph
  $\netgraph_t$ in the same fashion, except without a seed set. The resulting output of the second
  phase is the \osrank{}.
\end{itemize}

Care must be taken to ensure the seed set is large and well distributed enough such that
trajectories beginning from those verticies will reach all legitimate projects within the
network. There are many ways to maintain such a seed set. However, this will be elaborated
in future work.

\subsection{Implementation}

There exist several options for ensuring the \osrank{} computation
does not become prohibitively expensive for network operators to compute.

% TODO: Has "operators" been defined?

\begin{itemize}
\item \emph{Incremental Monte Carlo.} An incremental algorithm is used so that
  \osrank{} values may be updated as the network graph evolves. Instead of
  computing \osrank{} from scratch, we rely on the fact that only a small
  percentage of nodes or edges are modified
  from one calculation to the next (confirmed empirically on the datasets of
  major code-hosting platforms). Therefore, most of the random walks
  performed in the previous calculation remain valid in the updated graph. For
  example if only a single dependency $p_1 \xrightarrow[]{\dep} p_2$ has been
  added since the last calculation, then a random walk that was generated on the
  old graph is only invalid in the updated graph if it passes through $p_1$, for
  it may have chosen to follow this new dependency to $p_2$.

  % TODO: If we're going to say something is confirmed empirically we should have a citation

  In practice the operators of the network cache the set of random
  walks from the previous calculation, updating the set by removing
  invalid walks and replacing them with new ones. Details of such an
  incremental \pagerank{} algorithm can be found
  in \cite{incr pagerank}.

  Since all the computations must be deterministic, the walks are not
  truly random. Rather, they must use a built-in pseudo-random number
  generator to seed the random walks. The seed for generating
  random walks is fixed in the genesis block.

  % TODO: Add details on RNG

  % TODO: Entropy should be injected at each calculation from the underlying
  % consensus mechanism in order to ensure well sampled trajectories.

\item \emph{Long epoch.} In this scenario
  \osrank{}-based payouts are only made infrequently by choosing a large
  reward epoch $\epoch$ value, \eg once a month. In this case
  abusers might modify network structures of several projects in
  anticipation of the payout block. To mitigate this, edges are
  weighted by their lifetime since the last epoch. For
  example, if a dependency is added 1 block before the payout block,
  then it only has a weight proportional to $1/\epoch$.
\end{itemize}

\subsection{Conclusion}

Storing \osrank{} available on the ledger is fundamental to the \oscoin{}
``monetary policy'', as explained in \S \ref{s:treasury}. Furthermore,
\osrank{} and $\netgraph$ as a whole will be available to smart contracts
(\S\ref{s:smart-contracts}) so that projects can script custom behaviours using
this data.
