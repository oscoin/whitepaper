\section{Osrank}
\label{s:osrank}

\def\Graph{\mathsf{Graph}}
\def\proj{\mathsf{project}}
\def\contributor{\mathsf{account}}
\def\dep{\mathsf{depend}}
\def\own{\mathsf{maintain}}
\def\coown{\mathsf{maintain}^\circ}
\def\contrib{\mathsf{contrib}}
\def\cocontrib{\mathsf{contrib}^\circ}

Since one of the fundamental mechanisms of \oscoin{} is to distribute a portion
of the block reward ($B_r$) to high-value projects on the network, the protocol
must reach consensus on which projects are ``high value''. To choose which
projects receive \oscoin{}, and in which proportions, the network uses
\osrank{}, which is a variant of the well-know \pagerank{}
algorithm~\cite{pagerank}, applied to the graph of relationships between
projects and contributions on the network, particularly
\emph{dependencies} between projects. The output of the \osrank{} algorithm is a score
$\omega(P)$ associated to each project $P$.

\subsection{Intuition}

While the importance of an open source software package is highly subjective,
valuable information about a project's relative importance can be surfaced by
studying the structure of open source software through dependencies and
contributions.

Similarly to how Google pioneered a large-scale search engine around PageRank
that took advantage of the hypertextual structure of the Web, the graph of open
source software dependencies and contributions offers an important resource
that can be thought of as an implicit form of trust and relative value in the
ecosystem.

\subsection{Rationale}

While it may be clear that value is being produced by a system as a whole, it is
often unclear how much value particular subsystems are
contributing. Furthermore, subsystems have inherently differing capacities to
transform value into revenue: subsystems at the boundaries with other domains
are at an advantage, even though they may (transitively) derive much of their
value from other subsystems. This imbalance in value flows in and out of
subsystems is detrimental to the system as a whole.

Thankfully, human activity does not happen in a void\footnote{Space
  exploration will be addressed in a subsequent paper.}: be it
knowledge work, content/media creation, financial activity, etc.,
entities interact with one another in meaningful ways that are highly
influenced by the relative value each entity has with respect to the
system as a whole. Crucially, during this activity, a trail of
\emph{artefacts} (hypermedia links, contracts, transactions,
dependencies etc.) is produced; concrete manifestations
of the relationships between the various entities.

The basic insight of \pagerank{} and similar metrics, is that by
stochastic simulation of meaningful activity traces of system agents,
producing trails of artefacts consistent with observations, one can
learn about the value flows between subsystems, and hence approximate
the underlying value distribution. In the case of \pagerank{} one
simulates a human searching for high-relevance data over the Internet,
following a chain of links. A sophisticated algorithm would use as
many heuristics as possible for choosing the next link to follow (as a
real human would), \eg{} evaluating the relevance of the link-text. If
computational resources are scarce, the crudest algorithm simply picks
the next link at random, and this is what produces the classic
\pagerank{} formula which has proven so successful on the Web.

\subsection{Notation}

In this section we will use the following conventions: A \emph{graph} refers to
a finite directed graph. For such a graph $G$ the vertex set is denoted $V(G)$
and the edge-set is denoted $E(G) \subseteq V^2$. An edge $e = (x,y)$ of $G$ is
denoted $x \xrightarrow[]{e} y$. Given a subset $X$ of the vertices of $G$,
$G[X]$ denotes the \emph{induced subgraph} on $X$, that is, the graph with $X$
as the set of vertices and as edges the set
$\{ x \xrightarrow[]{e} y \mid e \in E(G), \{x,y\} \subseteq X\}$. A \emph{walk}
of length $n$ in a graph $G$ is a morphism of graphs $L_n \to G$ where $L_n$ is
the $n$-th linear-graph: $V(L_n) = \{i \in \mathbb{N} \mid i \leq n \}$,
$E(L_n) = \{ (i,i+1) \in \mathbb{N}^2 \mid i < n \}$.

\subsection{Ranking entities in \oscoin{}}
\label{s:netgraph}

The artefacts related to OSS development which are captured on the \oscoin{}
ledger are:
\begin{itemize}
  \item Maintenance of a project,
  \item Dependencies between projects,
  \item Signed code contributions to projects.
\end{itemize}
We summarize these interactions with a weighted directed graph $G$
(Figure~\ref{fig:G}), the weights corresponding to the relative importance of
the edge, which can be set as parameters to the algorithm.  The weights on all
edges outgoing from a vertex sum to $1$.

\begin{center}
\begin{tikzpicture}[vertex/.style={draw,circle,minimum width=8ex}, arr/.style={draw,thick,->}]
  \node[vertex] (p) at (2,0)  {\Small $\proj$};
  \node[vertex] (u) at (-2,0) {\Small $\contributor$};

  \draw[arr,looseness=7] (p) to[out=75,in=20] node[above] {\Small $\dep \ (\frac{4}{7})$} (p);
  \draw[arr] (p) to[out=165,in=15] node[above]   {\Small $\own \ (\frac{2}{7})$} (u);
  \draw[arr] (u) to[out=55,in=125] node[above]   {\Small $\coown \ (\frac{3}{5})$} (p);
  \draw[arr] (p) to[out=195,in=-15] node[below]  {\Small $\contrib \ (\frac{1}{7})$} (u);
  \draw[arr] (u) to[out=-55,in=-125] node[below] {\Small $\cocontrib \ (\frac{2}{5})$} (p);
\end{tikzpicture}
\captionof{figure}{\small Entity relations in open source software development with example weights.\label{fig:G}}
\end{center}
\medskip

% TODO: include simulations description and results here.

\noindent Note that some of the relationships are bidirectional, but each direction is
weighted uniquely. For example both $\contrib$ and $\cocontrib$ pertain to
the same artefact: a contribution of code from an account to a
project. The edge $\contrib$ represents the statement \emph{the contributor
is valuable to the project}. The edge $\cocontrib$ going in the
opposite direction represents the statement \emph{the project is
valuable to the contributor}; the rationale for this less obvious flow is
that developers are unlikely to invest time contributing to projects they
do not find useful.

% TODO: Make the above easier to grasp. Also maybe rephrase a little "is
% valueable to the project"

While the graph of dependencies between projects is the most straightforward
indication that a project derives value from another, adding edges corresponding
to contribution and maintenance serves two purposes:
\begin{itemize}
\item The graph is directed: it flows from user-facing applications to core
  libraries. This biases the score greatly towards basic libraries and
  development tools. Incorporating contributions brings flows in the
  opposite direction that indicate valued user-facing applications. For example,
  a fully-featured open source text editor is of high value to
  open source developers, yet it may never become an explicit dependency of another
  piece of software. However, developers contributing to this text editor are
  also likely to contribute to packages upon which the text editor depends, and this
  allows the algorithm to flow back up from libraries to user-facing
  packages. For example, an open source developer may contribute
  heavily to both the \texttt{atom} text editor (mostly JavaScript), and to
  one of its dependencies, \texttt{tree-sitter}, an incremental parser written
  in Rust.
\item While the dependency graph alone is unlikely to adequately bridge
  differing domains, developers often contribute to neighboring ecosystem and
  to tooling such that these niches can interconnect. Thus a graph incorporating
  dependencies as well as contributions may be sufficiently connected to
  reveal the latent value of open source projects.
\end{itemize}
We propose to record these artefacts as transactions in a blockchain, so that
one may verifiably construct---and reach consensus on---a finite directed graph
$\netgraph$ over $G$ (\ie{} in the slice category $\Graph/G$). We will refer to
$\netgraph$ as the \emph{network graph}.

This in turn allows global value scores to be assigned to entities
according to a specific stochastic process simulating \emph{random
  walks}, that is, activity traces in $\netgraph$ with sampling
probabilities taken from $G$. For example: a contributor decides to
work on a high value project, contributes a changeset, and in so doing adds a
dependency to another project, which imports a bug from an upstream package. The
contributor therefore switches to fixing said bug in the dependency, etc. Much
like a simulation of a human searching for information by clicking through
links, this simulated activity informs us on the value flows
between subsystems within the wider OSS ecosystem.

This score, which we call \osrank{}, is used to distribute a portion of the
newly minted tokens to projects as a function of their value to the \oscoin{}
network.

\subsection{Definition}

To implement \osrank{}, we use the following Monte Carlo-based algorithm: for
each vertex on the network, $R$ random walks are performed starting at that
vertex. To select the next vertex, first an edge type is decided
by sampling edges according to the weights in $G$. The next step is specific to
the type of edge:

\begin{itemize}
\item In the cases of $\dep$ and $\own$ edges, all vertices are equiprobable.
\item In the cases of edges $x \xrightarrow[]{\coown} p$ and
  $x \xrightarrow[]{\cocontrib} p$ outgoing from a contributor $x$, a project $p$ is
  chosen with probability $\frac{p_x}{N_x}$, where $p_x$ is the number of
  contributions $x$ has contributed to $p$, and $N_x$ is the total number of
  contributions by $x$.
\item In the case of edges $p \xrightarrow[]{\contrib} x$, the contributors $x$ are
  chosen with probability $\frac{p_x}{N}$, where $N$ is the total number of
  contributions $p$ has received from all contributors.
\end{itemize}

\noindent At each step the walk might terminate with probability $1 - \epsilon_\proj$ at a
project vertex, and $1 - \epsilon_\contributor$ at an account vertex, (here
$\epsilon_\proj, \epsilon_\contributor \in (0,1)$ are the \emph{damping factors}). This
produces a set $W$ of $nR$ random walks, where $n$ is the total number of
vertices. The \osrank{} for a project $x$ is then:
\[
  \omega(x) = \frac{W_x \epsilon_\proj}{n R}
\]
where $W_x$ is the number of times all the walks in $W$ visit $x$, that is:
\[
  W_x = \sum_{w \in W} |w[\{x\}]|.
\]
Similarly, the \osrank{} of an account $a$ is:
\[
  \omega(a) = \frac{W_a \epsilon_\contributor}{n R}.
\]

\subsection{Sybil networks}

In order to maintain the integrity of the \oscoin{} network graph, illegitimate
ecosystems must not be allowed to perpetuate, that is, fraudulent project and
contribution structures which have been instantiated for the purpose of
exploiting \osrank{} must be penalized by the algorithm.  Such \emph{Sybil attacks}
on \pagerank{} have been examined in detail in previous work
\cite{pagerank-sybil}.

To address this we propose a modification of the \pagerank{} algorithm based
on the ideas behind TrustRank~\cite{trustrank}, which involves two distinct
phases:

\begin{itemize}
\item In the first phase, all random walks begin at a vertex in the
  initialization seed set $\seedset$, a subset of all project and account
  vertices selected for this purpose.
  The scores obtained are biased towards interactions with the seed set, but
  they are not used directly by the compensation mechanism. Instead a threshold
  $t$ is used to determine the legitimacy of entities: any entity falling below
  this threshold is not considered for the next phase. The output of this phase
  is a subgraph $\netgraph_t$ of the network graph.
\item In the second phase, the algorithm is run on the subgraph $\netgraph_t$
  in the same fashion, except without a seed set. The resulting output of the
  second phase is the \osrank{}.
\end{itemize}
Care must be taken to ensure the seed set is large and well distributed enough
such that walks beginning from those vertices will reach all legitimate
projects within the network. There are many ways to maintain such a seed set.
However, this will be elaborated in future work.

\subsection{Information reliability and \osrank{}}

An important factor to consider when implementing \osrank{} is the reliablility
of information on the ledger, namely dependency information from which the
network graph $\netgraph$ is materialized.

It should be self-evident that \osrank{} cannot be a good proxy for value in
the network if the information on the ledger is not accurate. The algorithm can
tolerate a certain error margin, but we have to rely on a greater part of the
stated ``facts'' about dependencies and contributions on the ledger to be
correct and up to date. Without further work, there are certain intrinsic
social incentives for projects and maintainers to keep dependency information
up to date -- namely, dependency information is public and visible to everyone,
and projects have a reputation to withhold towards their dependents. All
projects carry the risk of being forked, given the financial incentives, and
therefore a certain amount of trust from the surrounding ecosystem is important --
trust that is earned by being a good citizen and providing accurate information
on the ledger, which allows upstream dependencies their fair share of the reward.

However, in the long term, these incentives might not be enough to stop dishonest
parties from taking advantage of the system. We briefly discuss potential
solutions in \S\ref{s:future-work}.

\subsection{Implementation}

There exist several options for ensuring the \osrank{} computation
does not become prohibitively expensive for network operators to compute.

\begin{itemize}
\item \emph{Incremental Monte Carlo.} An incremental algorithm is used so that
  \osrank{} values may be updated as the network graph evolves. Instead of
  computing \osrank{} from scratch, we rely on the fact that only a small
  percentage of vertices or edges are added or removed
  from one calculation to the next. Therefore, most of the random walks
  performed in the previous calculation remain valid in the updated graph. For
  example if only a single dependency $p_1 \xrightarrow[]{\dep} p_2$ has been
  added since the last calculation, then a random walk that was generated on the
  old graph is only invalidated in the updated graph if it passes through $p_1$.

  In practice the operators of the network cache the set of random
  walks from the previous calculation, updating the set by removing
  invalid walks and replacing them with new ones. Details of such an
  incremental \pagerank{} algorithm can be found
  in \cite{incr pagerank}.

  Since all the computations must be deterministic, the walks are not truly
  random. Rather, they must use a built-in pseudo-random number
  generator\footnote{Designing a suitable random number generator in the
  permissionless setting is an area of active research. Solutions exist
  which have been described in recent literature, and are beyond the
  scope of this paper.} to seed the random walks.

\item \emph{Long epoch.} In this scenario payouts according to
  \osrank{} are only made infrequently, by choosing a large value for the
  reward epoch $\epoch$, \eg{} monthly.  In this case
  abusers might modify network structures of several projects in
  anticipation of the payout block. To mitigate this, edges are
  weighted by their lifetime in the last epoch. For
  example, if a dependency is added $n$ blocks before the reward block,
  then it only has a weight proportional to $n/\epoch$.
\end{itemize}

\bigskip

\noindent Storing \osrank{} on the ledger is fundamental to the \oscoin{}
``monetary policy'', as explained in \S \ref{s:treasury}. Furthermore,
\osrank{} and $\netgraph$ as a whole will be available to smart contracts
(\S\ref{s:smart-contracts}) so that projects can script custom behaviors using
this data.
