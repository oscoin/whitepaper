\section{Osrank}
\label{s:osrank}

\def\Graph{\mathsf{Graph}}
\def\proj{\mathsf{proj}}
\def\user{\mathsf{user}}
\def\dep{\mathsf{dep}}
\def\own{\mathsf{own}}
\def\coown{\mathsf{own}^\circ}
\def\contrib{\mathsf{contrib}}
\def\cocontrib{\mathsf{contrib}^\circ}

Since one of the fundamental mechanisms of \oscoin{} is to distribute a portion
of newly minted tokens to high-value projects on the network, the protocol needs
to reach consensus on which projects are ``high value''. To choose which
projects receive compensation, and in which proportions, the network uses
\osrank{}, which is a modification of the well-know \pagerank{}
algorithm~\cite{pagerank} applied to the graph of relationships between projects
on the network, and in particular \emph{dependencies} between projects. The
output of the algorithm is a score $\omega(P)$ associated to each project
$P$.

\subsection{Rationale}

While it may be clear that value is being produced by a system as a whole, it is
often unclear how much value particular subsystems are
contributing. Furthermore, subsystems have inherently differing capacities to
transform value into revenue: subsystems at the boundaries with other domains
are at an advantage, even though they may (transitively) derive much of their
value from other subsystems. This disbalance in value flows in and out of
subsystems is detrimental to the system as a whole.

Thankfully, human activity does not happen in a void\footnote{Space
  exploration will be addressed in a subsequent paper.}: be it
knowledge work, content/media creation, financial activity, etc.,
entities interact with one another in meaningful ways that are highly
influenced by the relative value each entity has with respect to the
system as a whole. Crucially, during this activity, a trail of
\emph{artefacts} (hypermedia links, contracts, transactions,
dependencies, pull-requests etc.) is produced; concrete manifestations
of the relationships between the various entities.

The basic insight of \pagerank{} and similar metrics, is that by
stochastic simulation of meaningful activity traces of system agents,
producing trails of artefacts consistent with observations, one can
learn about the value flows between subsystems, and hence approximate
the underlying value distribution. In the case of \pagerank{} one
simulates a human searching for high-relevance data over the internet,
following a chain of links. A sophisticated algorithm would use as
many heuristics as possible for choosing the next link to follow (as a
real human would), \eg{} evaluating the relevance of the link-text. If
computational resources are scarce, the crudest algorithm simply picks
the next link at random, and this is what produces the classic
\pagerank{} formula which has seen so much success at ranking web
pages.

The artefacts related to OSS development which are captured on the \oscoin{}
ledger are:
\begin{itemize}
  \item Ownership of a project by a user,
  \item Dependencies between projects,
  \item Contributions of code from users to projects.
\end{itemize}

We summarise this these interactions with a weighted directed graph $G$
(Figure~\ref{fig:G}), the weights corresponding to the relative importance of
the edge, tweaked by our own judgement and informed by simulations we have
run.

% TODO: include simulations description and results here.

\begin{center}
\begin{tikzpicture}[vertex/.style={draw,circle}, arr/.style={draw,thick,->}]
  \node[vertex] (p) at (2,0)  {\small $\proj$};
  \node[vertex] (u) at (-2,0) {\small $\user$};

  \draw[arr,looseness=9] (p) to[out=95,in=25] node[above] {\small $\dep \ (4/7)$} (p);
  \draw[arr] (p) to[out=165,in=15] node[above]   {\small $\own \ (2/7)$} (u);
  \draw[arr] (u) to[out=55,in=125] node[above]   {\small $\coown \ (3/5)$} (p);
  \draw[arr] (p) to[out=195,in=-15] node[below]  {\small $\contrib \ (1/7)$} (u);
  \draw[arr] (u) to[out=-55,in=-125] node[below] {\small $\cocontrib \ (2/5)$} (p);
\end{tikzpicture}
\captionof{figure}{Graph or relations in between entities during OSS
  development.}
\label{fig:G}
\end{center}

The weights on all edges outgoing from a vertex sum to $1$.

Note that some of the edges are biderectional, but each direction gets
it's own weight. For example both $\contrib$ and $\cocontrib$ point to
the same artefact: a contribution of code from a user to a
project. The edge $\contrib$ represents the statement \emph{``the user
  is valuable to the project''}. The edge $\cocontrib$ going in the
opposite direction represents the statement \emph{``the project is
  valuable to the user''}; the rationale for this less obvious flow is
that users are unlikely to invest time contributing to a project they
don't find useful.

% TODO: include similations data.

The \oscoin{} network proposes to record these artefacts as
transactions in a blockchain, so that one may unambiguously rebuild
(and reach consensus on) a finite directed graph $\netgraph$ over $G$
(\ie{} in the slice category $\Graph/G$). We'll refer to $\netgraph$
as the \emph{network graph}.

This in turn allows global value scores to be assigned to entities
according to a specific stochastic process simulating \emph{random
  walks}, that is, activity traces in $\netgraph$ with sampling
probabilities taken from $G$. For example: a contributor decides to
work on a high value project (probably at the border), contributes a
PR, in so doing adds a dependency to another project, which imports a
bug from upstream. The contributor therefore switches to fixing said
bug in the dependency, etc. Much like a simulation of a human
searching for information by clicking through links, this simulated
contributor activity informs us on the value flows between subsystems
in OSS development.

This score, which we call \osrank{}, is used to weight the
distribution of newly minted tokens to high value entities, thus
compensating entities which bring value to the ecosystem.

More specifically we use the following Monte Carlo-based algorithm:
for each project on the network, $R$ random walks are performed which
start at that node and proceed by sampling outgoing edges, according
to the weights declared in $G$. At each step the walk might terminate
with probability $1 - \epsilon$, (here $\epsilon$ is the \emph{damping
  factor}, $0 < \epsilon < 1$). This produces a set $W$ of walks. The
\osrank{} for a project $x$ is then:
\[
  s(x) = \frac{W_x \epsilon}{n R}
\]
where $W_x$ is the number of visits of $x$, over all walks, that is:
\[
W_x = \sum_{w \in W} v(w,x)
\]
where $v(w,x)$ is the number of times path $w$ visits the vertex $x$.

\subsection{Fake ecosystems}

The main problem to avoid is compensating fake ecosystems, that is,
project structures and relationships which have been setup in the
network graph for the sole purpose of gaming the \osrank{} algorithm.

For this we propose running \osrank{} in two distinct phases:
\begin{itemize}
\item In the first phase, a seed set $S$ is used as the for the
  beginning of all walks. Specifically, a random walk always starts at
  a vertex in $S$. Otherwise the process remains the same. The scores
  obtained are biased towards interactions with the seed set, but they
  are not used directly by the compensation mechanism. Instead a
  threashold $t$ is used to determine the legitimacy of entities: any
  entity falling below this threshold is not considered for the next
  phase. One obtains a subgraph of the network graph $\netgraph_t$.
\item In the seconds phase, the algorithm is ran on the subgraph
  $\netgraph_t$ as usual, with no seed set. The output of the second
  phase is the \osrank{}.
\end{itemize}

% TODO: remove the term governance.
We propose that the seed set be maintained by an on-chain governance
system, aiming to choose high-value user-facing projects,
e.g. Firefox, Debian, VLC, etc. Care must be taken to ensure the seed
set is large enough to touch most legitimate projects on the network.

\subsection{Implementation}

There are several options for making sure the computation of \osrank{}
will not be prohibitively expensive for operators to run.

\begin{itemize}
\item \emph{Incremental Monte Carlo.} An incremental algorithm is used
  so that \osrank{} values may be updated as the network graph
  evolves. Instead of computing \osrank{} from scratch, we rely on the
  fact that only a small percentage of the nodes and edges of the
  network graph are added or removed from one calculation to the next
  (confirmed empirically on the datasets of major code-hosting
  platforms). Therefore most of the random walks that were performed
  in the previous calculation remain valid in the updated graph. For
  example if only a single dependency $x \to y$ has been added, then a
  walk is invalid only if passes through $x$, for it may have chosen
  to follow this new dependency.

  In practice the operators of the network cache the set of random
  walks from the previous calculation, and update this set by removing
  invalid walks and replacing them with new ones. Details on such an
  incremental algorithm used in the case of \pagerank{} can be found
  in \cite{incr pagerank}.

  Since all the computations must be deterministic, the walks are not
  truly random. Rather, they must use a built-in pseudo-random number
  generator to generate the random walks. The seed for generating
  random walks is fixed in the genesis block.

  % TODO: Add details on RNG

\item \emph{Long epoch.} In this scenario payouts according to
  \osrank{} are only made infrequently, say with a duration of $d$
  between \emph{payout} blocks (e.g.\ once every month). In this case
  abusers might modify network structures of several projects in
  anticipation of the payout block. To mitigate this, some edges are
  weighted by the amount of time it has existed in the last epoch. For
  example, if a dependency is added a day before the payout block,
  then it only has a wight proportional to $1/d$.
\end{itemize}
